{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# í•™ìŠµ ê°€ì´ë“œ ì—ì´ì „íŠ¸\n",
        "\n",
        "ì‚¬ìš©ìê°€ ë°°ìš°ê³  ì‹¶ì€ ì£¼ì œë¥¼ ì…ë ¥í•˜ë©´ ë‹¨ê³„ë³„ í•™ìŠµ ê³„íšì„ ìë™ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "%pip install langchain langchain-openai langchain-community tavily-python python-dotenv python-docx -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/miniconda3/envs/hateslop/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".env íŒŒì¼ ê²½ë¡œ: /Users/mac/Desktop/hateslop/hateslop_hackathon/.env\n",
            "Tavily API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
            "API í‚¤ (ì²˜ìŒ 10ì): tvly-dev-d...\n",
            "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
            "API í‚¤ (ì²˜ìŒ 10ì): sk-proj-x2...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
        "from langchain import hub\n",
        "\n",
        "# .env íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
        "env_path = Path.cwd() / \".env\"\n",
        "if not env_path.exists():\n",
        "    env_path = Path(\"uuyeong/.env\")\n",
        "    if not env_path.exists():\n",
        "        env_path = Path(__file__).parent / \".env\" if \"__file__\" in globals() else Path.cwd() / \"uuyeong/.env\"\n",
        "\n",
        "# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
        "load_dotenv(dotenv_path=env_path)\n",
        "print(f\".env íŒŒì¼ ê²½ë¡œ: {env_path.absolute()}\")\n",
        "\n",
        "# API í‚¤ í™•ì¸\n",
        "if \"TAVILY_API_KEY\" not in os.environ or os.environ[\"TAVILY_API_KEY\"] == \"YOUR_KEY\":\n",
        "    print(\"ê²½ê³ : TAVILY_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "    print(\"uuyeong/.env íŒŒì¼ì—ì„œ TAVILY_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\")\n",
        "else:\n",
        "    print(\"Tavily API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "    print(f\"API í‚¤ (ì²˜ìŒ 10ì): {os.environ['TAVILY_API_KEY'][:10]}...\")\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ or os.environ[\"OPENAI_API_KEY\"] == \"YOUR_KEY\":\n",
        "    print(\"ê²½ê³ : OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "    print(\"uuyeong/.env íŒŒì¼ì—ì„œ OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.\")\n",
        "else:\n",
        "    print(\"OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "    print(f\"API í‚¤ (ì²˜ìŒ 10ì): {os.environ['OPENAI_API_KEY'][:10]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## í•™ìŠµ ê°€ì´ë“œ ì—ì´ì „íŠ¸ ì„¤ì •\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tavily ê²€ìƒ‰ Toolì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
            "ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/xt/6hqj9_8d223c_wq515gdl8m80000gn/T/ipykernel_12767/701134673.py:2: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
            "  tavily_tool_guide = TavilySearchResults(\n"
          ]
        }
      ],
      "source": [
        "# Tavily ê²€ìƒ‰ Tool ìƒì„± (í•™ìŠµ ìë£Œ ê²€ìƒ‰ìš©)\n",
        "tavily_tool_guide = TavilySearchResults(\n",
        "    api_key=os.environ.get(\"TAVILY_API_KEY\", \"YOUR_KEY\"),\n",
        "    max_results=10  # í•™ìŠµ ìë£Œë¥¼ ë” ë§ì´ ìˆ˜ì§‘\n",
        ")\n",
        "\n",
        "print(\"Tavily ê²€ìƒ‰ Toolì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "print(f\"ìµœëŒ€ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {tavily_tool_guide.max_results}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## í•™ìŠµ ê°€ì´ë“œ ì—ì´ì „íŠ¸ ìƒì„±\n",
        "\n",
        "í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê¸°ë²•ì„ í™œìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ í•™ìŠµ ê³„íšì„ ìƒì„±í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "í•™ìŠµ ê°€ì´ë“œ ì—ì´ì „íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
            "ì‚¬ìš© ê°€ëŠ¥í•œ Tool: ['tavily_search_results_json']\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "import json\n",
        "import re\n",
        "\n",
        "# LLM ì´ˆê¸°í™”\n",
        "llm_guide = ChatOpenAI(model=\"gpt-4-turbo\", temperature=0)\n",
        "\n",
        "# ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸° (agent_scratchpad í¬í•¨)\n",
        "base_prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "\n",
        "# ì‹œìŠ¤í…œ ë©”ì‹œì§€ ìˆ˜ì • (Role Prompting + Few-shot + CoT)\n",
        "# ì£¼ì˜: JSON ì˜ˆì‹œì˜ ì¤‘ê´„í˜¸ëŠ” {{ }}ë¡œ ì´ìŠ¤ì¼€ì´í”„í•´ì•¼ í•¨\n",
        "custom_system_message = \"\"\"ë„ˆëŠ” ê²½í—˜ì´ í’ë¶€í•œ êµìœ¡ ì „ë¬¸ê°€ì´ì í•™ìŠµ ì„¤ê³„ìì•¼.\n",
        "\n",
        "ì‚¬ìš©ìê°€ ë°°ìš°ê³  ì‹¶ì€ ì£¼ì œì— ëŒ€í•´ ë‹¤ìŒ ì›ì¹™ì„ ë”°ë¼ í•™ìŠµ ê°€ì´ë“œë¥¼ ì‘ì„±í•´:\n",
        "\n",
        "1. **ë‹¨ê³„ë³„ êµ¬ì„±**: ê¸°ì´ˆ â†’ ì¤‘ê¸‰ â†’ ê³ ê¸‰ ìˆœì„œë¡œ ë‹¨ê³„ë¥¼ ë‚˜ëˆ \n",
        "2. **ì‹¤ìš©ì ì¸ ì‹œê°„ ë°°ë¶„**: ì´ˆë³´ì ê¸°ì¤€ìœ¼ë¡œ ê° ë‹¨ê³„ì— ì ì ˆí•œ ì‹œê°„ ë°°ë¶„\n",
        "3. **ê²€ì¦ëœ ìë£Œ ì¶”ì²œ**: ìµœì‹ ì´ë©´ì„œë„ ê²€ì¦ëœ êµì¬ì™€ ì‚¬ì´íŠ¸ ì¶”ì²œ\n",
        "4. **êµ¬ì²´ì ì¸ íˆ¬ë‘ë¦¬ìŠ¤íŠ¸**: ê° ë‹¨ê³„ë§ˆë‹¤ ì²´í¬ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ í•  ì¼ ëª©ë¡\n",
        "\n",
        "[ì¶œë ¥ í˜•ì‹]\n",
        "ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´:\n",
        "{{\n",
        "  \"topic\": \"ì£¼ì œëª…\",\n",
        "  \"total_duration_days\": ì´_í•™ìŠµ_ì¼ìˆ˜,\n",
        "  \"start_date\": \"ì‹œì‘ì¼ (YYYY-MM-DD)\",\n",
        "  \"end_date\": \"ì¢…ë£Œì¼ (YYYY-MM-DD)\",\n",
        "  \"steps\": [\n",
        "    {{\n",
        "      \"step_number\": 1,\n",
        "      \"title\": \"ë‹¨ê³„ ì œëª©\",\n",
        "      \"duration_days\": ë‹¨ê³„ë³„_ì¼ìˆ˜,\n",
        "      \"start_date\": \"ì‹œì‘ì¼ (YYYY-MM-DD)\",\n",
        "      \"end_date\": \"ì¢…ë£Œì¼ (YYYY-MM-DD)\",\n",
        "      \"learning_content\": [\"í•™ìŠµ ë‚´ìš© 1\", \"í•™ìŠµ ë‚´ìš© 2\"],\n",
        "      \"recommended_books\": [\"êµì¬ 1\", \"êµì¬ 2\"],\n",
        "      \"recommended_sites\": [\n",
        "        {{\"name\": \"ì‚¬ì´íŠ¸ëª…\", \"url\": \"URL\"}}\n",
        "      ],\n",
        "      \"todos\": [\"íˆ¬ë‘ 1\", \"íˆ¬ë‘ 2\", \"íˆ¬ë‘ 3\"]\n",
        "    }}\n",
        "  ]\n",
        "}}\n",
        "\n",
        "ì¤‘ìš”: JSON í˜•ì‹ë§Œ ì¶œë ¥í•˜ê³ , ì¶”ê°€ ì„¤ëª…ì€ í•˜ì§€ ë§ˆ.\"\"\"\n",
        "\n",
        "# í”„ë¡¬í”„íŠ¸ ë©”ì‹œì§€ ìˆ˜ì • (ì‹œìŠ¤í…œ ë©”ì‹œì§€ êµì²´)\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "# ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ì˜ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë©´ì„œ ì‹œìŠ¤í…œ ë©”ì‹œì§€ë§Œ êµì²´\n",
        "learning_guide_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", custom_system_message),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
        "    (\"human\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "])\n",
        "\n",
        "# Agent ìƒì„±\n",
        "tools_guide = [tavily_tool_guide]\n",
        "agent_guide = create_openai_tools_agent(llm_guide, tools_guide, learning_guide_prompt)\n",
        "agent_executor_guide = AgentExecutor(agent=agent_guide, tools=tools_guide, verbose=False)  # verbose=Falseë¡œ ì„¤ì •í•˜ì—¬ ì¶œë ¥ ê°„ì†Œí™”\n",
        "\n",
        "print(\"í•™ìŠµ ê°€ì´ë“œ ì—ì´ì „íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "print(f\"ì‚¬ìš© ê°€ëŠ¥í•œ Tool: {[tool.name for tool in tools_guide]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## í•™ìŠµ ê°€ì´ë“œ ìƒì„± í•¨ìˆ˜\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### í•™ìŠµ ê°€ì´ë“œ ìƒì„± ë° íŒŒì‹±\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "í•™ìŠµ ê°€ì´ë“œ ìƒì„± í•¨ìˆ˜ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "def create_learning_guide(topic: str, start_date: str = None):\n",
        "    \"\"\"\n",
        "    í•™ìŠµ ê°€ì´ë“œë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜\n",
        "    \n",
        "    Args:\n",
        "        topic: í•™ìŠµí•˜ê³  ì‹¶ì€ ì£¼ì œ\n",
        "        start_date: ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD í˜•ì‹, Noneì´ë©´ ì˜¤ëŠ˜)\n",
        "    \n",
        "    Returns:\n",
        "        í•™ìŠµ ê°€ì´ë“œ ë”•ì…”ë„ˆë¦¬\n",
        "    \"\"\"\n",
        "    if start_date is None:\n",
        "        start_date = datetime.now().strftime('%Y-%m-%d')\n",
        "    \n",
        "    # Agent ì‹¤í–‰\n",
        "    query = f\"'{topic}'ë¥¼ ë°°ìš°ê³  ì‹¶ì–´. ë‹¨ê³„ë³„ í•™ìŠµ ê³„íšì„ ë§Œë“¤ì–´ì¤˜. ì˜¤ëŠ˜ì€ {start_date}ì•¼.\"\n",
        "    \n",
        "    print(f\"ğŸ“š '{topic}' í•™ìŠµ ê°€ì´ë“œ ìƒì„± ì¤‘...\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    result = agent_executor_guide.invoke({\"input\": query})\n",
        "    output = result[\"output\"]\n",
        "    \n",
        "    print(\"\\nâœ… ê²€ìƒ‰ ì™„ë£Œ! í•™ìŠµ ê°€ì´ë“œë¥¼ ìƒì„±í•˜ëŠ” ì¤‘...\\n\")\n",
        "    \n",
        "    # JSON ì¶”ì¶œ ì‹œë„\n",
        "    try:\n",
        "        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ\n",
        "        if \"```json\" in output:\n",
        "            json_str = output.split(\"```json\")[1].split(\"```\")[0].strip()\n",
        "        elif \"```\" in output:\n",
        "            json_str = output.split(\"```\")[1].split(\"```\")[0].strip()\n",
        "        else:\n",
        "            # JSON ë¶€ë¶„ë§Œ ì°¾ê¸°\n",
        "            json_match = re.search(r'\\{.*\\}', output, re.DOTALL)\n",
        "            if json_match:\n",
        "                json_str = json_match.group(0)\n",
        "            else:\n",
        "                raise ValueError(\"JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        \n",
        "        guide = json.loads(json_str)\n",
        "        print(\"âœ… í•™ìŠµ ê°€ì´ë“œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\\n\")\n",
        "        return guide\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}\")\n",
        "        print(\"\\nì›ë³¸ ì¶œë ¥:\")\n",
        "        print(output)\n",
        "        return {\"raw_output\": output, \"error\": str(e)}\n",
        "\n",
        "print(\"í•™ìŠµ ê°€ì´ë“œ ìƒì„± í•¨ìˆ˜ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### í•™ìŠµ ê°€ì´ë“œ ì¶œë ¥ í•¨ìˆ˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "í•™ìŠµ ê°€ì´ë“œ ì¶œë ¥ í•¨ìˆ˜ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "def print_learning_guide(guide: dict):\n",
        "    \"\"\"í•™ìŠµ ê°€ì´ë“œë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥\"\"\"\n",
        "    if \"error\" in guide:\n",
        "        print(guide[\"raw_output\"])\n",
        "        return\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"ğŸ“– í•™ìŠµ ì£¼ì œ: {guide.get('topic', 'N/A')}\")\n",
        "    print(f\"ğŸ“… í•™ìŠµ ê¸°ê°„: {guide.get('start_date', 'N/A')} ~ {guide.get('end_date', 'N/A')}\")\n",
        "    print(f\"â±ï¸  ì´ í•™ìŠµ ì¼ìˆ˜: {guide.get('total_duration_days', 'N/A')}ì¼\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    for step in guide.get(\"steps\", []):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"ğŸ“Œ {step.get('step_number', 'N/A')}ë‹¨ê³„: {step.get('title', 'N/A')}\")\n",
        "        print(f\"   ê¸°ê°„: {step.get('start_date', 'N/A')} ~ {step.get('end_date', 'N/A')} ({step.get('duration_days', 'N/A')}ì¼)\")\n",
        "        print(f\"\\n   ğŸ“š í•™ìŠµ ë‚´ìš©:\")\n",
        "        for content in step.get(\"learning_content\", []):\n",
        "            print(f\"      â€¢ {content}\")\n",
        "        \n",
        "        if step.get(\"recommended_books\"):\n",
        "            print(f\"\\n   ğŸ“– ì¶”ì²œ êµì¬:\")\n",
        "            for book in step.get(\"recommended_books\", []):\n",
        "                print(f\"      â€¢ {book}\")\n",
        "        \n",
        "        if step.get(\"recommended_sites\"):\n",
        "            print(f\"\\n   ğŸŒ ì°¸ê³  ì‚¬ì´íŠ¸:\")\n",
        "            for site in step.get(\"recommended_sites\", []):\n",
        "                if isinstance(site, dict):\n",
        "                    print(f\"      â€¢ {site.get('name', 'N/A')}: {site.get('url', 'N/A')}\")\n",
        "                else:\n",
        "                    print(f\"      â€¢ {site}\")\n",
        "        \n",
        "        if step.get(\"todos\"):\n",
        "            print(f\"\\n   âœ… íˆ¬ë‘ë¦¬ìŠ¤íŠ¸:\")\n",
        "            for todo in step.get(\"todos\", []):\n",
        "                print(f\"      â˜ {todo}\")\n",
        "\n",
        "print(\"í•™ìŠµ ê°€ì´ë“œ ì¶œë ¥ í•¨ìˆ˜ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### íˆ¬ë‘ë¦¬ìŠ¤íŠ¸ ìƒì„± í•¨ìˆ˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "íˆ¬ë‘ë¦¬ìŠ¤íŠ¸ ìƒì„± í•¨ìˆ˜ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "def generate_todo_markdown(guide: dict) -> str:\n",
        "    \"\"\"í•™ìŠµ ê°€ì´ë“œì—ì„œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ íˆ¬ë‘ë¦¬ìŠ¤íŠ¸ ìƒì„±\"\"\"\n",
        "    if \"error\" in guide:\n",
        "        return \"ê°€ì´ë“œê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"\n",
        "    \n",
        "    markdown = f\"# {guide.get('topic', 'í•™ìŠµ')} íˆ¬ë‘ë¦¬ìŠ¤íŠ¸\\n\\n\"\n",
        "    markdown += f\"**í•™ìŠµ ê¸°ê°„**: {guide.get('start_date', 'N/A')} ~ {guide.get('end_date', 'N/A')}\\n\"\n",
        "    markdown += f\"**ì´ í•™ìŠµ ì¼ìˆ˜**: {guide.get('total_duration_days', 'N/A')}ì¼\\n\\n\"\n",
        "    \n",
        "    for step in guide.get(\"steps\", []):\n",
        "        step_title = f\"{step.get('step_number', 'N/A')}. {step.get('title', 'N/A')}\"\n",
        "        step_date = f\"{step.get('start_date', 'N/A')} ~ {step.get('end_date', 'N/A')}\"\n",
        "        \n",
        "        markdown += f\"## {step_title}\\n\"\n",
        "        markdown += f\"**ê¸°ê°„**: {step_date}\\n\\n\"\n",
        "        \n",
        "        for todo in step.get(\"todos\", []):\n",
        "            markdown += f\"- [ ] {todo}\\n\"\n",
        "        \n",
        "        markdown += \"\\n\"\n",
        "    \n",
        "    return markdown\n",
        "\n",
        "print(\"íˆ¬ë‘ë¦¬ìŠ¤íŠ¸ ìƒì„± í•¨ìˆ˜ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ì›Œë“œ íŒŒì¼ ìƒì„± í•¨ìˆ˜\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì›Œë“œ íŒŒì¼ ìƒì„± í•¨ìˆ˜ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "from docx import Document\n",
        "from docx.shared import Pt, RGBColor, Inches\n",
        "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
        "from datetime import datetime\n",
        "\n",
        "def save_learning_guide_to_word(guide: dict, filename: str = None) -> str:\n",
        "    \"\"\"\n",
        "    í•™ìŠµ ê°€ì´ë“œë¥¼ ì›Œë“œ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜\n",
        "    \n",
        "    Args:\n",
        "        guide: í•™ìŠµ ê°€ì´ë“œ ë”•ì…”ë„ˆë¦¬\n",
        "        filename: ì €ì¥í•  íŒŒì¼ëª… (Noneì´ë©´ ìë™ ìƒì„±)\n",
        "    \n",
        "    Returns:\n",
        "        ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ\n",
        "    \"\"\"\n",
        "    if \"error\" in guide:\n",
        "        print(\"âŒ ê°€ì´ë“œê°€ ìƒì„±ë˜ì§€ ì•Šì•„ ì›Œë“œ íŒŒì¼ì„ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "        return None\n",
        "    \n",
        "    # íŒŒì¼ëª… ìƒì„±\n",
        "    if filename is None:\n",
        "        topic = guide.get('topic', 'í•™ìŠµê°€ì´ë“œ').replace(' ', '_')\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        filename = f\"{topic}_í•™ìŠµê°€ì´ë“œ_{timestamp}.docx\"\n",
        "    \n",
        "    # ì›Œë“œ ë¬¸ì„œ ìƒì„±\n",
        "    doc = Document()\n",
        "    \n",
        "    # ì œëª© ìŠ¤íƒ€ì¼ ì„¤ì •\n",
        "    title = doc.add_heading(f\"{guide.get('topic', 'í•™ìŠµ ê°€ì´ë“œ')} í•™ìŠµ ê°€ì´ë“œ\", 0)\n",
        "    title.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
        "    \n",
        "    # ê¸°ë³¸ ì •ë³´\n",
        "    doc.add_paragraph(f\"í•™ìŠµ ê¸°ê°„: {guide.get('start_date', 'N/A')} ~ {guide.get('end_date', 'N/A')}\")\n",
        "    doc.add_paragraph(f\"ì´ í•™ìŠµ ì¼ìˆ˜: {guide.get('total_duration_days', 'N/A')}ì¼\")\n",
        "    doc.add_paragraph(\"\")  # ë¹ˆ ì¤„\n",
        "    \n",
        "    # ê° ë‹¨ê³„ë³„ ë‚´ìš©\n",
        "    for step in guide.get(\"steps\", []):\n",
        "        # ë‹¨ê³„ ì œëª©\n",
        "        step_title = doc.add_heading(\n",
        "            f\"{step.get('step_number', 'N/A')}ë‹¨ê³„: {step.get('title', 'N/A')}\", \n",
        "            level=1\n",
        "        )\n",
        "        \n",
        "        # ê¸°ê°„ ì •ë³´\n",
        "        period_para = doc.add_paragraph()\n",
        "        period_para.add_run(f\"ê¸°ê°„: \").bold = True\n",
        "        period_para.add_run(\n",
        "            f\"{step.get('start_date', 'N/A')} ~ {step.get('end_date', 'N/A')} \"\n",
        "            f\"({step.get('duration_days', 'N/A')}ì¼)\"\n",
        "        )\n",
        "        doc.add_paragraph(\"\")  # ë¹ˆ ì¤„\n",
        "        \n",
        "        # í•™ìŠµ ë‚´ìš©\n",
        "        if step.get(\"learning_content\"):\n",
        "            doc.add_paragraph(\"í•™ìŠµ ë‚´ìš©:\", style='Heading 2')\n",
        "            for content in step.get(\"learning_content\", []):\n",
        "                para = doc.add_paragraph(content, style='List Bullet')\n",
        "            doc.add_paragraph(\"\")  # ë¹ˆ ì¤„\n",
        "        \n",
        "        # ì¶”ì²œ êµì¬\n",
        "        if step.get(\"recommended_books\"):\n",
        "            doc.add_paragraph(\"ì¶”ì²œ êµì¬:\", style='Heading 2')\n",
        "            for book in step.get(\"recommended_books\", []):\n",
        "                para = doc.add_paragraph(book, style='List Bullet')\n",
        "            doc.add_paragraph(\"\")  # ë¹ˆ ì¤„\n",
        "        \n",
        "        # ì°¸ê³  ì‚¬ì´íŠ¸\n",
        "        if step.get(\"recommended_sites\"):\n",
        "            doc.add_paragraph(\"ì°¸ê³  ì‚¬ì´íŠ¸:\", style='Heading 2')\n",
        "            for site in step.get(\"recommended_sites\", []):\n",
        "                if isinstance(site, dict):\n",
        "                    para = doc.add_paragraph()\n",
        "                    para.add_run(f\"{site.get('name', 'N/A')}: \").bold = True\n",
        "                    para.add_run(site.get('url', 'N/A'))\n",
        "                else:\n",
        "                    doc.add_paragraph(str(site), style='List Bullet')\n",
        "            doc.add_paragraph(\"\")  # ë¹ˆ ì¤„\n",
        "        \n",
        "        # íˆ¬ë‘ë¦¬ìŠ¤íŠ¸\n",
        "        if step.get(\"todos\"):\n",
        "            doc.add_paragraph(\"íˆ¬ë‘ë¦¬ìŠ¤íŠ¸:\", style='Heading 2')\n",
        "            for todo in step.get(\"todos\", []):\n",
        "                para = doc.add_paragraph(todo, style='List Bullet')\n",
        "            doc.add_paragraph(\"\")  # ë¹ˆ ì¤„\n",
        "        \n",
        "        # ë‹¨ê³„ êµ¬ë¶„ì„ \n",
        "        doc.add_paragraph(\"â”€\" * 50)\n",
        "        doc.add_paragraph(\"\")  # ë¹ˆ ì¤„\n",
        "    \n",
        "    # íŒŒì¼ ì €ì¥\n",
        "    doc.save(filename)\n",
        "    print(f\"âœ… ì›Œë“œ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {filename}\")\n",
        "    return filename\n",
        "\n",
        "print(\"ì›Œë“œ íŒŒì¼ ìƒì„± í•¨ìˆ˜ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ì‚¬ìš© ì˜ˆì‹œ\n",
        "\n",
        "ì•„ë˜ ì…€ì—ì„œ ì›í•˜ëŠ” ì£¼ì œë¥¼ ì…ë ¥í•˜ì—¬ í•™ìŠµ ê°€ì´ë“œë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“š 'ë¨¸ì‹ ëŸ¬ë‹' í•™ìŠµ ê°€ì´ë“œ ìƒì„± ì¤‘...\n",
            "============================================================\n",
            "\n",
            "âœ… ê²€ìƒ‰ ì™„ë£Œ! í•™ìŠµ ê°€ì´ë“œë¥¼ ìƒì„±í•˜ëŠ” ì¤‘...\n",
            "\n",
            "âœ… í•™ìŠµ ê°€ì´ë“œê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
            "\n",
            "\n",
            "âœ… 'ë¨¸ì‹ ëŸ¬ë‹' í•™ìŠµ ê°€ì´ë“œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
            "ğŸ“… í•™ìŠµ ê¸°ê°„: 2025-12-04 ~ 2026-03-03\n",
            "â±ï¸  ì´ í•™ìŠµ ì¼ìˆ˜: 90ì¼\n",
            "ğŸ“Œ ì´ 3ë‹¨ê³„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.\n",
            "\n",
            "âœ… ì›Œë“œ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: ë¨¸ì‹ ëŸ¬ë‹_í•™ìŠµê°€ì´ë“œ_20251204_155811.docx\n",
            "\n",
            "ğŸ“„ ì „ì²´ ë‚´ìš©ì€ ì›Œë“œ íŒŒì¼ì—ì„œ í™•ì¸í•˜ì„¸ìš”: ë¨¸ì‹ ëŸ¬ë‹_í•™ìŠµê°€ì´ë“œ_20251204_155811.docx\n"
          ]
        }
      ],
      "source": [
        "# ì—¬ê¸°ì— ì›í•˜ëŠ” í•™ìŠµ ì£¼ì œë¥¼ ì…ë ¥í•˜ì„¸ìš”\n",
        "my_topic = \"ë¨¸ì‹ ëŸ¬ë‹\"  # ì˜ˆ: \"Python í”„ë¡œê·¸ë˜ë°\", \"ì›¹ ê°œë°œ\", \"ë°ì´í„° ë¶„ì„\", \"ëœ¨ê°œì§ˆ\", \"Cì–¸ì–´\" ë“±\n",
        "\n",
        "# í•™ìŠµ ê°€ì´ë“œ ìƒì„±\n",
        "my_guide = create_learning_guide(my_topic)\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥ (ê°„ë‹¨íˆ)\n",
        "if \"error\" not in my_guide:\n",
        "    print(f\"\\nâœ… '{my_guide.get('topic', 'N/A')}' í•™ìŠµ ê°€ì´ë“œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
        "    print(f\"ğŸ“… í•™ìŠµ ê¸°ê°„: {my_guide.get('start_date', 'N/A')} ~ {my_guide.get('end_date', 'N/A')}\")\n",
        "    print(f\"â±ï¸  ì´ í•™ìŠµ ì¼ìˆ˜: {my_guide.get('total_duration_days', 'N/A')}ì¼\")\n",
        "    print(f\"ğŸ“Œ ì´ {len(my_guide.get('steps', []))}ë‹¨ê³„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.\\n\")\n",
        "    \n",
        "    # ì›Œë“œ íŒŒì¼ë¡œ ì €ì¥\n",
        "    word_file = save_learning_guide_to_word(my_guide)\n",
        "    print(f\"\\nğŸ“„ ì „ì²´ ë‚´ìš©ì€ ì›Œë“œ íŒŒì¼ì—ì„œ í™•ì¸í•˜ì„¸ìš”: {word_file}\")\n",
        "else:\n",
        "    print(\"âŒ í•™ìŠµ ê°€ì´ë“œ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
        "    print(my_guide.get(\"raw_output\", \"\"))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "hateslop",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
